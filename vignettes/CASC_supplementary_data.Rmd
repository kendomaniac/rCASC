---
title: "CASC supplementary data"
author: "Luca Alessandr√¨, Marco Beccuti, Maddalena Arigoni, Martina Olivero, Greta Romano, Luigia Pace, Francesca Cordero and Raffaele A Calogero"
date: "8/21/2018"
output: pdf_document

toc: yes
header-includes:
- \usepackage{makeidx}
- \makeindex
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'h')
```

## **Section 1** CASC: a single cell analysis workflow designed to provide data reproducibility

Because of the massive data generation given by the omics platforms the [*reproducibility crisis*](https://en.wikipedia.org/wiki/Replication_crisis) is becoming a very important issue [[*Nature, 6 July 2018*](https://www.nature.com/collections/prbfkwmwvz)] and there is a mandatory need to to guarantee robust and reliable results to the research community [[*Global Engage Blog*](http://www.global-engage.com/life-science/reproducibility-computational-biology/)].
\newline
Our group is deeply involved in developing workflows that guarantee both **functional** (i.e. the information about data and the utilized tools are saved in terms of meta-data) and **computation** reproducibility (i.e. the real image of the computation environment used to generate the data is stored). For this reason we are managing a bioinformatics community called [*reproducible-bioinformatics.org*](http://www.reproducible-bioinformatics.org/) [*Kulkarni et al. BMC Bioinformatics, in press*] designed to provide to the biological community a reproducible bioinformatics ecosystem  [[*Beccuti et al. Bioinformatics 2018*](https://academic.oup.com/bioinformatics/article/34/5/871/4562334)]. 
\newline
CASC, Cluster Analysis of Single Cells, is part of the [*reproducible-bioinformatics.org*](http://www.reproducible-bioinformatics.org/) project and provides single cell analysis functionalities within the reproducible rules described by Sandve et al. [[*PLoS Comp Biol. 2013*](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285)]. CASC is designed to provide a complete workflow (Figure \ref{fig:fig.1}) for cell-subpopulation discovery. 

```{r fig.1, fig.cap="CASC workflow", echo=FALSE, eval=TRUE, out.width="70%", fig.align="center"}
library(knitr)

include_graphics('../inst/img/casc_workflow.jpeg')

```


The workflow allows the direct analysis of fastq files generated with [*10X Genomics platform*](https://www.10xgenomics.com/) or [*InDrop technology*](https://1cell-bio.com/) or a count matrix having as column cell identifier and as row names ENSEMBL gene annotation. In the following paragraphs we will describe the fuctionalities of CASC workflow.
\newline


### **Section 1.1** Minimal hardware requirements to run CASC
The RAM and cores requirements are dependent on the data set under analysis, e.g. 500-600 cells can be effectively analysed using the hardware described by Beccuti [[*Bioinformatics 2018*](https://academic.oup.com/bioinformatics/article/34/5/871/4562334)]: 32 Gb RAM and 2.6 GHz Core i7 6700HQ with 8 threads. The analysis time can be significantly improved increasing the number of cores using a multi-core achitecture system, cluster implementation of the workflow using [*swarm*](https://docs.docker.com/engine/swarm/) is under implementation. 

### **Section 1.2** Installation

You need to have docker installed on your machine, for more info see this document:

[*https://docs.docker.com/engine/installation/*](https://docs.docker.com/engine/installation/).

**CASC** package is expected to run on 64 bits linux machine with at least 4 cores. A scratch folder should be present, e.g. /data/scratch and it should be writable from everybody:

```
chmod 777 /data/scratch
```

The functions in CASC package require that user is part of a docker group.
See the following document for more info:
[*https://docs.docker.com/install/linux/linux-postinstall/*](https://docs.docker.com/install/linux/linux-postinstall/)

\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}


install.packages("devtools")
library(devtools)
install_github("kendomaniac/casc")

# downloading the required containers
library(casc)
downloadContainers()


```
\fontsize{10}{10}\selectfont



## **Section 2** Counts generation

### **Section 2.1** inDrop seq

inDrop was originally pulished by Klein [[*Cell 2015*](https://www.ncbi.nlm.nih.gov/pubmed/26000487)]. Then, two year after that, the authors published the detailed protocol in [[*Zilionis et al. Nature Protocols 2017*](https://www.ncbi.nlm.nih.gov/pubmed/27929523)], which has different primer design comparing to the orginal paper (Figure \ref{fig:fig.2}). 

```{r fig.2, fig.cap="inDrop library structure", echo=FALSE, eval=TRUE, out.width="80%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/indrop_v2.jpeg')
```


The analysis shown below is based on the protocol in Zilionis [[*Nature Protocols 2017*](https://www.ncbi.nlm.nih.gov/pubmed/27929523)], which is the version 2 of the inDrop technology. According to the [*inDrop github page*](https://github.com/indrops/indrops), there is a version 3, but the oligos and library structures are exactly the same as version 2, except the sequencing mode changed.

In version 2, three different reads are generated: 

```{r fig.3, fig.cap="inDrop v2", echo=FALSE, eval=TRUE, out.width="80%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/indropv2.jpg')
```


In version 3, four different reads are generated:

```{r fig.4, fig.cap="inDrop v3", echo=FALSE, eval=TRUE, out.width="80%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/indropv3.jpg')
```



#### **Section 2.1.1** inDrop data analysis

- **inDropseq**:
    + Creating a reference genome for inDrop V2: **indropIndex**
    + From fastq to UMI counts using inDrop workflow: **indropCounts**


The function *indropIndex* is available to generate the index files required for reads mapping and annotation.
\newline
\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

library(casc)
#running indropCounts index build
indropIndex(group="docker", index.folder=getwd(),
 ensembl.urlgenome="ftp://ftp.ensembl.org/pub/release-87/fasta/mus_musculus/dna/Mus_musculus.GRCm38.dna.toplevel.fa.gz",
ensembl.urlgtf="ftp://ftp.ensembl.org/pub/release-87/gtf/mus_musculus/Mus_musculus.GRCm38.87.gtf.gz")

```

\fontsize{10}{10}\selectfont
The function *indropCounts* starts from inDrop V2 library fastqs and generates UMI counts.
\newline
\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

system("wget 130.192.119.59/public/testMm_S0_L001_R1_001.fastq.gz")
system("wget 130.192.119.59/public/testMm_S0_L001_R2_001.fastq.gz")
library(casc)
indropCounts(group="docker", scratch.folder="/data/scratch", fastq.folder=getwd(),
        index.folder="/data/genomes/indropMm10", sample.name="testMm", split.affixes="S0_L001",
        bowtie.index.prefix="genome", M=10, U=2, D=400, low.complexity.mask="False")

```
\fontsize{10}{10}\selectfont

### **Section 2.2** 10XGenomics

- **10XGenomics**:
    + Downloading a reference genome for 10XGenomics
    + Converting fastq in UMI counts matrix using cellranger: **cellrangerCount**


[Cellranger](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/algorithms/overview) is the 10xGenomics tool allowing the conversion of the fastq generated from 10XGenomics platform into a count matrix. 

Genome indexes downloadable from 10Xgenomics repository:
\newline
\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}
setwd("/data/genomes/cellranger_hg38")
#getting the hg38 human genome cellranger index 
system("wget http://cf.10xgenomics.com/supp/cell-exp/refdata-cellranger-GRCh38-2.1.0.tar.gz")
setwd("/data/genomes/cellranger_hg19")
#getting the hg19 human genome cellranger index
system("wget http://cf.10xgenomics.com/supp/cell-exp/refdata-cellranger-hg19-2.1.0.tar.gz")
setwd("/data/genomes/cellranger_mm10")
#getting the mm10 mouse genome cellranger index
system("wget http://cf.10xgenomics.com/supp/cell-exp/refdata-cellranger-mm10-2.1.0.tar.gz")
setwd("/data/genomes/cellranger_hg19mm10")
#getting the human and mouse cellranger index
system("wget http://cf.10xgenomics.com/supp/cell-exp/refdata-cellranger-hg19-and-mm10-2.1.0.tar.gz")
```

\fontsize{10}{10}\selectfont
The function *cellrangerCount* starts from 10Xgenomics library fastqs and generates UMI counts.
\newline
\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

home <- getwd()
library(casc)
downloadContainers()
setwd("/data/genomes/cellranger_hg19mm10")
#getting the human and mouse cellranger index
system("wget http://cf.10xgenomics.com/supp/cell-exp/refdata-cellranger-hg19-and-mm10-2.1.0.tar.gz")
setwd(home)
# downloading 100 cells 1:1 Mixture of Fresh Frozen Human (HEK293T) and Mouse (NIH3T3) Cells
system("wget http://cf.10xgenomics.com/samples/cell-exp/2.1.0/hgmm_100/hgmm_100_fastqs.tar")
system("tar xvf hgmm_100_fastqs.tar")
# The cellranger analysis is run without the generation of the secondary analysis
cellrangerCount(group="docker",  transcriptome.folder="/data/genomes/cellranger_hg19mm10",  
                fastq.folder="/data/test_cell_ranger/fastqs",  expect.cells=100, 
                nosecondary=TRUE, scratch.folder="/data/scratch")
```
\fontsize{10}{10}\selectfont
 
The analysis done above took 56.4 mins on an [*SeqBox*](www.seqbox.com), equipped with an Intel i7-6770HQ (8 threads), 32 Gb RAM and 1Tb SSD.

The output of the above analysis are two cell counts matrices **results_cellranger.cvs** and **results_cellranger.txt** and a folder called **results_cellranger**, which contains the full cellranger output.

## **Section 3** Counts matrix editing

This paragraph describes a set of functions that can be used to remove low quality cells and non-informative genes.

- **Counts manipulation**:
    + Removing non informative genes: **filterZeros**
    + Checking the genes versus total number of UMI: **genesUmi**
    + Removing low quality cells: **lorenzFilter**
    + Data normalization: **scnorm**, minimal requirements 10K counts/cell, works best with whole transcriptome sequencing
    + Data normalization: **umiNorm**, global normalization methods TMM and RLE are suitable for UMI data
    + ENSEMBL annotation and mitochodrial/ribosomal protein genes removal: **scannobyGtf**
    + Converting a count table in log10: **counts2log**
    + Removing cell cycle bias: **recatPrediction**/**ccremove**



### **Section 3.1** Removing non informative genes

The function **filterZeros** retains all genes that have cells without a user defined fraction of zeros (between 0 and 1, where 1 indicate only genes without 0s are retained, and 0 insted indicates that genes with at least a value different from zero are retained) and plots the frequency distribution of genes with counts in the cells. 

**IMPORTANT**: In case user would like to apply cell quality filter, e.g. *lorenzFilter*, it is covenient to remove only genes with 0 counts in all cells, i.e. threshold=0 (Figure \ref{fig:fig.5}).
\newline
\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

system("wget http://130.192.119.59/public/testSCumi_mm10.csv.zip")
unzip("testSCumi_mm10.csv.zip")
tmp <- read.table("testSCumi_mm10.csv", sep=",", header=T, row.names=1)
dim(tmp)
#27998   806
write.table(tmp, "testSCumi_mm10.txt", sep="\t", col.names=NA)
filterZeros(data.folder=getwd(),counts.matrix="testSCumi_mm10.txt", threshold=0)
#Out of 27998 genes 11255 are left after removing genes with no counts
#output is filtered_testSCumi_mm10.txt

```
\fontsize{10}{10}\selectfont

```{r fig.5, fig.cap="Non zeros distribution in full table, orange, and filtered table, blue", echo=FALSE, eval=TRUE, out.width="40%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/filterZero.jpeg')
```

### **Section 3.2** Plotting genes numbers versus total UMIs in each cell

To estimate the overall amount of genes detectable in each cell, the function *genesUmi* produces a plot of the genes number with respect to total number of UMI for each cell. The number of UMIs required to indicate that a gene is detected in a cell are defined by user. We suggest to use at least 3 UMI as minimal threshold to consider a gene called present in a cell.

\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

library(casc)
genesUmi(data.folder=getwd(), counts.matrix="filtered_testSCumi_mm10.txt", umiXgene=3)

```
\fontsize{10}{10}\selectfont

In figure \ref{fig:fig.6} it is shown the distribution of genes in cells for filtered_testSCumi_mm10.txt counts table. 

```{r fig.6, fig.cap="genesUmi output", echo=FALSE, eval=TRUE, out.width="40%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/genesUMI.jpg')
```

#### **Section 3.2.1** Some considerations about the number of reads/UMI to be used in a single-cell sequencing experiment.

[*Ziegenhain and coworkers*](https://www.ncbi.nlm.nih.gov/pubmed/28212749) published a comparison between single cell sequencing protocols and they show that, in a simulated experiment, at least 250K reads/UMI are requested for detecting at least 80% of differentially expressed genes between two groups (Figure \ref{fig:fig.6.1}). This information is clearly very important in case we are interested to cluster cells to detect differences between sub-populations. The choise of the sequencing method and of the sequencing depth might strongly affect the ability to discriminate between sub-populations.

```{r fig.6.1, fig.cap="Modified from Figure 6. Power of scRNA-Seq Methods of Ziegenhain et al. (Mol. Cell 2017). For more information on the experiment please see Ziegenhain et al. (Mol. Cell 2017)", echo=FALSE, eval=TRUE, out.width="50%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/Ziegenhain2017.jpeg')
```

The sequencing depth affects the number of detectable genes, which are the key element to discriminate between sub-populations. In Figure \ref{fig:fig.6.2} we show the effect of sequencing depth on the number of detectable genes in 10XGenomics sequencing experiments at different depths (25K reads/cell extracted from CD19 B-cells [[*Zheng et al*](https://community.10xgenomics.com/t5/Data-Sharing/10x-Single-Cell-3-Paper-Zheng-et-al-2016-Datasets/td-p/231)],  83K reads/cell fextracted from GSM2833284_Naive_WT_Rep1 [[*Pace et al. 2018*](https://www.ncbi.nlm.nih.gov/pubmed/29326266)] and 250K reads/cell from an unpublished mouse experiment) and one whole transcriptome sequencing experiment [[*Buettner et al Nat.Biotechnol. 2015*](https://www.ncbi.nlm.nih.gov/pubmed/25599176)] with a 3.5 milion median reads/cell. To make the datasets comparable we run the analysis on 288 randomly selected cells from each data set. We use  3 UMI as minimal threshold to consider a gene called present in 10XGenomics experiments and 5 reads [[*Tarazona et al. 2011*](https://genome.cshlp.org/content/21/12/2213.long)] as minimal threshold to consider a gene called present in a cell whole trasncriptome experiment.  


\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}
system("wget http://130.192.119.59/public/Zheng_cd19_288cells.txt.zip")
unzip("Zheng_cd19_288cells.txt.zip")
library(casc)
genesUmi(data.folder=getwd(), counts.matrix="Zheng_cd19_288cells.txt", umiXgene=3)
system("mv genes.umi.pdf genes.umi_25k.pdf")

system("wget http://130.192.119.59/public/GSM2833284_Naive_WT_Rep1_288cell.txt.zip")
unzip("GSM2833284_Naive_WT_Rep1_288cell.txt.zip")
library(casc)
genesUmi(data.folder=getwd(), counts.matrix="GSM2833284_Naive_WT_Rep1_288cell.txt", umiXgene=3)
system("mv genes.umi.pdf genes.umi_86k.pdf")

system("wget http://130.192.119.59/public/brain_unpublished_288cells.txt.zip")
unzip("brain_unpublished_288cells.txt.zip")
library(casc)
genesUmi(data.folder=getwd(), counts.matrix="brain_unpublished_288cells.txt", umiXgene=3)
system("mv genes.umi.pdf genes.umi_250k.pdf")


system("wget http://130.192.119.59/public/buettner_G1G2MS_counts.txt.zip")
unzip("buettner_G1G2MS_counts.txt.zip")
library(casc)
genesUmi(data.folder=getwd(), counts.matrix="buettner_G1G2MS_counts.txt", umiXgene=5)
system("mv genes.umi.pdf genes.umi_3.5M.pdf")

```
\fontsize{10}{10}\selectfont

Figure \ref{fig:fig.6.2} clearly show that the number of detectable genes that can be obtained by 10XGenomics sequencing is, even with 250K reads/cell (Figure \ref{fig:fig.6.2}C), far less of those detectable using a whole transcriptome experiment (Figure \ref{fig:fig.6.2}D). Furthermore, it is clear that a depth below 250K reads/cell will allow efficent cell clustering only if large differences exists between cell sub-populations.

```{r fig.6.2, fig.cap="Number of detected genes with respect to mapped reads. A) 25K reads/cell 10XGenomics platform, 3\' end sequencing. B) 86K reads/cell 10XGenomics platform, 3\' end sequencing. C) 250K reads/cell 10XGenomics platform, 3\' end sequencing. D) 3.5 milion reads/cell C1 platform, whole transcriptome sequencing", echo=FALSE, eval=TRUE, out.width="50%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/seq_depth.jpeg')
```


### **Section 3.3** Identifying and removing cell low-quality outliers

To identify outlier libraries, Diaz and coworkers [[*2016*](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4937196/)] developed a strategy to estimate genes expressed at background levels in a given sample. Then samples whose background fraction is significantly larger than average is filtered out (Lorenz statistics). Specifically, samples that had a small q-value for Lorenz statistic had low complexity, as measured by Gini-Simpson index, and/or they had low coverage, as estimated by the Good-Turing statistic [[*Diaz et al. 2016*](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4937196/)]. Furthermore, Lorenz statistics correlates with live-dead staining, Pearson-correlation 0.7 [[*Diaz et al. 2016*](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4937196/)]. We have implemented the Lorenz statistics in CASC **lorenzFilter** function.
\newline
\fontsize{8}{8}\selectfont
```{r, echo=TRUE,eval=FALSE}

#IMPORTANT: full path to the file MUST be cell count file included!
library(casc)
# the p_value indicate the probability that a low quality cell is retained in the 
# dataset filtered on the basis of Lorenz Statistics.
lorenzFilter(group="docker",scratch.folder="/data/scratch/", 
               file=paste(getwd(),"filtered_testSCumi_mm10.txt", sep="/"),
               p_value=0.05, separator='\t')

tmp0 <- read.table("filtered_testSCumi_mm10.txt", sep="\t", header=T, row.names=1)
#806 cells

tmp <- read.table("lorenz_filtered_testSCumi_mm10.txt", sep="\t", header=T, row.names=1)
#785 cells

```
\fontsize{10}{10}\selectfont


In the example above 21 cells were removed because of their low quality (Figure \ref{fig:fig.7}). 

```{r fig.7, fig.cap="Effect of Lorenz filtering, cells shown in blue have been discarded because of their low quality.", echo=FALSE, eval=TRUE, out.width="40%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/lorenz_filter.jpg')
```

### **Section 3.4** Annotation and mitocondrial/ribosomal protein genes removal

The function *scannoByGtf* allows the annotation of single-cell matrix, if ENSEMBL gene ids are provided. The function requires the ENSEMBL GTF of the organism under analysis and allows the selection of specific annotation biotypes, e.g. protein_coding.
\newline
\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

#running annotation and removal of mito and ribo proteins genes
system("wget ftp://ftp.ensembl.org/pub/release-92/gtf/mus_musculus/Mus_musculus.GRCm38.92.gtf.gz")
system("gunzip Mus_musculus.GRCm38.92.gtf.gz")
scannobyGtf(group="docker", file=paste(getwd(),"lorenz_filtered_testSCumi_mm10.txt",sep="/"),
                    gtf.name="Mus_musculus.GRCm38.92.gtf", biotype="protein_coding", 
                    mt=TRUE, ribo.proteins=TRUE,umiXgene=3)

```
\fontsize{10}{10}\selectfont

Ribosomal RNA and ribosomal proteins represent a significant part of the cell cargo. Large cells and actively proliferating cells will have respectively more ribosomes and more active ribosome synthesis. Thus, ribosomal proteins expression might represent a major confunding factor in cluster formation between active and dormient cells. Furthermore, the main function of mitochondria is to produce energy through aerobic respiration. The number of mitochondria a cell possesses depends on its metabolic demands. This might also affect clustering favoring the separation between active and dormient cells with respect to functional differences between subpopulations.
*scannobyGtf* allows also the removal of mitocondrial and ribosomal protein genes.
\newline
\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

library(casc)
scannobyGtf(group="docker", file=paste(getwd(),"lorenz_filtered_testSCumi_mm10.txt",sep="/"),
                    gtf.name="Mus_musculus.GRCm38.92.gtf", biotype="protein_coding", 
                    mt=FALSE, ribo.proteins=FALSE,umiXgene=3)

```
\fontsize{10}{10}\selectfont

In figure \ref{fig:fig.8} is shown the effect of the removal of both mitocondrial and ribosomal protein genes. It is notable that, in this specific experiment, in cells with less than 1000 UMI nearly all detected genes were only mitocondrial and ribosomal protein genes. This filter is suitable to identify cells which do not contain any informative gene other the mitocondrial and ribosomal proteins. However, in case the difference between resting and actively proliferating cells are an important element of cell sub-population discovery this filter should not be applied.

```{r fig.8, fig.cap="Removing mithocondrial and ribosomal proteins genes, in red is shown the dataset after removal of mitocondrial and ribosomal protein genes.", echo=FALSE, eval=TRUE, out.width="40%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/noMT-rib.jpg')
```


### **Section 3.5** Top expressed genes

For clustering purposes user might decide to use the top expressed genes. The function *topX* select the X top expressed genes given a user defined threshold. The function also produces a pdf file gene_expression_distribution.pdf showing the changes in the UMIs/gene expression distribution upon *topX* filtering.

\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}
 
library(casc)
genesUmi(data.folder=getwd(), counts.matrix="lorenz_filtered_testSCumi_mm10.txt", umiXgene=3)
topx(data.folder=getwd(),file.name="lorenz_filtered_testSCumi_mm10.txt",threshold=10000, logged=FALSE)
genesUmi(data.folder=getwd(), counts.matrix="lorenz_filtered_testSCumi_mm10_10000.txt", umiXgene=3)

```
\fontsize{10}{10}\selectfont

### **Section 3.6** Data normalization

[*The best way to normalize single-cell RNA-seq data has not yet been resolved*](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5549838/), expecially in the case of UMI data. We inserted in our workflow two possible options:

- [SCnorm](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5473255/), which works best with whole transcript data.

- [scone](https://www.biorxiv.org/content/early/2017/12/16/235382), which provides different global scaling methods that can be applyed to UMI single-cell data.

#### **Section 3.6.1** SCnorm

[*SCnorm*](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5473255/) performs a quantile-regression based approach for robust normalization of single-cell RNA-seq data.  SCnorm groups genes based on their count-depth relationship then applies a quantile regression to each group in order to estimate scaling factors which will remove the effect of sequencing depth from the counts.

IMPORTANT: SCnorm is not intended for datasets with more than ~80% zero counts, because of lack of algoritm convergency in these situations. 

##### **Section 3.6.1.1** Check counts-depth relationship

Before normalizing using **scnorm**, it is advised to check the data count-depth relationship.
If all genes have a similar relationship then a global normalization strategy such as median-by-
ratio in the DESeq package or TMM in edgeR will also be adequate. However, when the count-depth relationship varies among genes using global scaling strategies leads to poor normalization. In these cases the normalization provided by SCnorm is recommended.

**checkCountDepth** provides a wrapper, in CASC, for the checkCountDepth of the [*SCnorm package*](https://github.com/rhondabacher/SCnorm), which estimates the count-depth relationship for all genes.
\newline
\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

#this specific example is an UMI counts table made of 12 cells having at least 10K UMIs/cell.
system("wget http://130.192.119.59/public/example_UMI.txt.zip")
unzip("example_UMI.txt.zip")
conditions=rep(1,12)
checkCountDepth(group="docker", file=paste(getwd(), "example_UMI.txt", sep="/"),
     conditions=conditions, FilterCellProportion=0.1, FilterExpression=0,
     ditherCounts=TRUE, outputName="example_UMI", nCores=8)

```
\fontsize{10}{10}\selectfont

The output is a PDF (Figure \ref{fig:fig.9}), providing a view of the counts distribution of the data, and a file selected.genes.txt, which contains the genes selected to run the analysis.

```{r fig.9, fig.cap="checkCountDepth output plot", echo=FALSE, eval=TRUE, out.width="40%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/checkCountDepth0.jpg')
```



##### **Section 3.6.1.2** scnorm

the **scnorm** function execute SCnorm from [*SCnorm package*](https://github.com/rhondabacher/SCnorm), which normalizes  across  cells  to  remove  the effect  of  sequencing  depth  on  the  counts  and  return  the  normalized expression count.
\newline
\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

system("wget http://130.192.119.59/public/example_UMI.txt.zip")
unzip("example_UMI.txt.zip")
#this specific example is an UMI counts table made of 12 cells having at least 10K UMIs/cell.
conditions=rep(1,12)
scnorm(group="docker", file=paste(getwd(), "example_UMI.txt", sep="/"),
     conditions=conditions,outputName="example_UMI", nCores=8, filtercellNum=10,
     ditherCount=TRUE, PropToUse=0.1, PrintProgressPlots=TRUE, FilterExpression=1)

```
\fontsize{10}{10}\selectfont

The output files are a tab delimited file containing the normalized data, with the prefix **normalized_**, **discarded_genes.txt**, which contains the discarded genes, and a plot of the normalization effects ((Figure \ref{fig:fig.10})).

```{r fig.10, fig.cap="Effect of the SCnorm on the dataset in Figure 9", echo=FALSE, eval=TRUE, out.width="40%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/scnorm.jpeg')
```

**scnorm** is compliant with [*SIMLR*](https://www.ncbi.nlm.nih.gov/pubmed/28263960), the CASC core clustering tool.

#### **Section 3.6.2** scone

scone package embeds:

- Centered log-ratio (**CLR**) normalization 

- Relative log-expression (**RLE**; DESeq) scaling normalization

    + the scaling factors are calculated for each lane as median of the ratio, for each gene, of its read count of its geometric mean across all lanes. 

- Full-quantile normalization

    + quantile normalization is a technique for making two or more distributions identical in statistical properties. To quantile normalize two or more samples to each other, sort the samples, then set to the average (usually, arithmetic mean) of the samples. So the highest value in all cases becomes the mean of the highest values, the second highest value becomes the mean of the second highest values, and so on.

- Simple deconvolution normalization 

- Sum scaling normalization

    + Gene counts are divided by the total number of mapped reads (or library size) associated with their lane and multiplied by the mean total count across all the samples of the dataset.

- Weighted trimmed mean of M-values (**TMM**, edgeR) scaling normalization (suitable for single-cell)

    + to compute the TMM factor, one lane is considered a reference sample and the others test samples, with TMM being the weighted mean of log ratios between test and reference, after excluding the most expressed genes and the genes with the largest log ratios. 

- Upper-quartile (**UQ**) scaling normalization

    + the total counts are replaced by the upper quartile of counts different from 0 in the computation of the normalization factors.

\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

#Weighted trimmed mean of M-values (TMM) scaling normalization
system("wget http://130.192.119.59/public/example_UMI.txt.zip")
unzip("example_UMI.txt.zip")
umiNorm(group="docker", file=paste(getwd(), "example_UMI.txt", sep="/"),
       outputName="example_UMI", normMethod="TMM_FN")

```
\fontsize{10}{10}\selectfont


**IMPORTANT**: In case sub-population discovery is the analysis task, it is important to check if a specific normalization is compliant with the clustering approach in use. For example in the case of [*SIMLR*](https://www.ncbi.nlm.nih.gov/pubmed/28263960), the CASC core clustering tool, the normalizations provided in **scone** remove some of the features required to run the multikernel learning analysis. TMM is instead compliant with the CASC implementation of [**tSne**](https://lvdmaaten.github.io/tsne/).

### **Section 3.7** Converting a count table in log10

The function **counts2log** can convert a count table in a log10 values saved in a comma separated or tab delimited file.

\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

counts2log(file=paste(getwd(), "example_UMI.txt", sep="/"), log.base=10)

```
\fontsize{10}{10}\selectfont


### **Section 3.8** Removing cell cycle bias

Single-cell RNA-Sequencing measurement of expression often suffers from large systematic bias. A major source of this bias is the cell cycle, which introduces large within-cell-type heterogeneity that can obscure the differences in expression between cell types. [*Barron and Li*](https://www.nature.com/articles/srep33892) developed in 2016 a R package called [*ccRemover*](https://cran.r-project.org/web/packages/ccRemover/index.html) which removes cell cycle effects and preserves other biological signals of interest (Figure \ref{fig:fig.11}).


```{r fig.11, fig.cap="Removal of cell cycle bias as described in Barron and Li. [Sci. Rep. 2016]. A) PCA analysis of Buettner et al. (Nat.Biotechnol. 2015) raw dataset, B) PCA analysis of ccRemover cell-cycle normalized dataset. Figure edited from supplementary data in Barron and Li [Sci. Rep. 2016].", echo=FALSE, eval=TRUE, out.width="50%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/barron2016.jpeg')
```


However, the critical point is if it is really needed the removal of cell cycle effect. [*reCAT*](https://www.nature.com/articles/s41467-017-00039-z) is a modelling framework for unsynchronized single-cell transcriptome data that can reconstruct cell cycle time-series.  Thus, reCAT cell cycle prediction step can be used to check if  a clear cell cycle effect in a dataset (Figure \ref{fig:fig.12}) can be detected and therefore ccRemover normalization approach will be needed.


```{r fig.12, fig.cap="reCAT prediction of cell cycle in Buettner et al. (Nat.Biotechnol. 2015) dataset. Figure extracted from reCAT github", echo=FALSE, eval=TRUE, out.width="40%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/ola_2i_bayes.png')
```


- **Removing cell cycle bias**:
    + Reconstructing cell cycle time-series: **recatPrediction**
    + Removing cell cycle effect: **ccRemove**

**reCAT** prediction step is implemented in CASC in the function **recatPrediction**, which requires a data set annotated using **scannobyGtf**.

**ccRemover** software is implemented in CASC in the function **ccRemove**, which also requires a data set annotated using **scannobyGtf**.

**IMPORTANT**: The output of ccRemover does not require log transformation to be used in clustering analysis.

To show the differences existing between a dataset characterized by cell clycle bias and one that is not, we used two datasets:

- the dataset published by [*Buettner et al Nat.Biotechnol. 2015*](https://www.ncbi.nlm.nih.gov/pubmed/25599176), containing naive-T-cells and T-helper2-cells mixed togheter and sorted on the basis of the cell cycle state. 

- The quescent naive T-cell dataset part of the pubblication of [*Pace et al. Science 2018*](https://www.ncbi.nlm.nih.gov/pubmed/?term=29326266), expected to be in G0. 

To execute the analysis on the same number of cells, 288 cells were randomly selected from quescent naive T-cell dataset. In Figure \ref{fig:fig.13}A the presence of oscillatory behaviour is evident in the predicted cells time serie and the G1 and G2M trends are indicated respectively in blue and red dashed courves. On the other hand the oscillatory behaviour is totally absent (Figure \ref{fig:fig.13}B) in the naive T-cells, which are expected to be quiescent in G0.

```{r fig.13, fig.cap="Cell cycle assigment to the cells. A) Buettner et al. (Nat.Biotechnol. 2015) raw dataset, cells are expected to be distributed in G1, S and G2M, B) Naive T-cells, expected to be mainly in G0.", echo=FALSE, eval=TRUE, out.width="70%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/recat1.jpeg')
```


\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

#preparing the data for the analysis
 system("wget http://130.192.119.59/public/buettner_G1G2MS_counts.txt.zip")
 unzip("buettner_G1G2MS_counts.txt.zip")

#annotatiing the data set to obtain the gene names in the format ensemblID:symbol 
scannobyGtf(group="docker", file=paste(getwd(),"buettner_G1G2MS_counts.txt",sep="/"),
                    gtf.name="Mus_musculus.GRCm38.92.gtf", biotype="protein_coding", 
                    mt=TRUE, ribo.proteins=TRUE,umiXgene=3)

#selecting the top 10000 most expressed genes
topx(data.folder=getwd(),file.name="annotated_buettner_G1G2MS_counts.txt",threshold=10000, logged=FALSE)

#running cell cycle prediction
recatPrediction(group="docker",scratch.folder="/data/scratch",file=paste(getwd(), "annotated_buettner_G1G2MS_counts_10000.txt", sep="/"), 
                separator="\t", geneNameControl=1, window=10, seed=111)

#removing cell cycle effect
ccRemove(group="docker" , scratch.folder="/data/scratch",
        file=paste(getwd(),"annotated_buettner_G1G2MS_counts_10000.txt", sep="/"), separator="\t",
        seed=111, cutoff=3, species="mouse", rawCount=1)

#same analysis as above on 10XGenomix data of quescent naive-T cells
system("wget http://130.192.119.59/public/GSM2833284_Naive_WT_Rep1_288cell.txt.zip")
unzip("GSM2833284_Naive_WT_Rep1_288cell.txt.zip")
scannobyGtf(group="docker", file=paste(getwd(),"GSM2833284_Naive_WT_Rep1_288cell.txt",sep="/"),
                    gtf.name="Mus_musculus.GRCm38.92.gtf", biotype="protein_coding", 
                    mt=TRUE, ribo.proteins=TRUE,umiXgene=3)
topx(data.folder=getwd(),file.name="annotated_GSM2833284_Naive_WT_Rep1_288cell.txt",threshold=10000, logged=FALSE)
recatPrediction(group="docker",scratch.folder="/data/scratch",file=paste(getwd(), "annotated_GSM2833284_Naive_WT_Rep1_288cell_10000.txt", sep="/"), separator="\t", geneNameControl=1, window=10, seed=111)


```

\fontsize{10}{10}\selectfont

The analyses above were done using using a [SeqBox](www.seqbox.com), equipped with an Intel i7-6770HQ (8 threads), 32 Gb RAM and 1Tb SSD. They took  54 and 40 mins for recatPrediction respectively on Buettner and the naive T-cell datasets. 28 mins were needed by ccRemove on Buettner data set. ccRemover analysis produces a data normalized matrix, ready for clustering. The matrix can be identify by the prefix **LS_cc_**.
**ccRemove** output is compliant with [*SIMLR*](https://www.ncbi.nlm.nih.gov/pubmed/28263960), the CASC core clustering tool. **ccRemove** output does not require log transformation when applied to SIMLR.

\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

#visualizing the dataset before and after cell cycle bias removal
#reformat the matrix header to be suitable with docker4seq PCA plotting function
tmp <- read.table("annotated_buettner_G1G2MS_counts_10000.txt", sep="\t", header=T, row.names=1)
tmp.n1 <- sapply(tmp.n, function(x)x[1])
tmp.n2 <- sapply(tmp.n, function(x)x[2])
names(tmp) <- paste(tmp.n2, tmp.n1, sep="_")
write.table(tmp, "annotated_buettner_G1G2MS_counts_10000bis.txt", sep="\t", col.names=NA)

library(devtools)
install_github("kendomaniac/docker4seq", ref="master")
library(docker4seq)

pca(experiment.table="annotated_buettner_G1G2MS_counts_10000bis.txt", type="counts", 
      legend.position="topright", covariatesInNames=TRUE, samplesName=FALSE,
      principal.components=c(1,2), pdf = TRUE, 
      output.folder=getwd())

#reformat the matrix header to be suitable with docker4seq PCA plotting function
tmp <- read.table("LS_cc_annotated_buettner_G1G2MS_counts_10000.txt", sep="\t", header=T, row.names=1)
tmp.n1 <- sapply(tmp.n, function(x)x[1])
tmp.n2 <- sapply(tmp.n, function(x)x[2])
names(tmp) <- paste(tmp.n2, tmp.n1, sep="_")
write.table(tmp, "LS_cc_annotated_buettner_G1G2MS_counts_10000bis.txt", sep="\t", col.names=NA)

pca(experiment.table="LS_cc_annotated_buettner_G1G2MS_counts_10000bis.txt", type="TPM", 
      legend.position="topright", covariatesInNames=TRUE, samplesName=FALSE,
      principal.components=c(1,2), pdf = TRUE, 
      output.folder=getwd())


```
\fontsize{10}{10}\selectfont

In Figure \ref{fig:fig.14} are shown the results obtained using the ccRemove implementation in CASC, using the Buettner dataset. The removal of the cell cycle effect (Figure \ref{fig:fig.14}B) is clearly shown by a reduction of the variance explained by PC1 and PC2 in the PCA plot.

```{r fig.14, fig.cap="As Figure 11, but done with CASC implementation of the ccRemove. A) PCA analysis of Buettner et al. (Nat.Biotechnol. 2015) raw dataset, B) PCA analysis of ccRemove cell-cycle normalized dataset.", echo=FALSE, eval=TRUE, out.width="70%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/buettner_raw_ccremover.jpeg')
```

## **Section 4** Estimating the number of cluster to be used for cell sub-population discovery.

The CASC core clustering tool is [*SIMLR*](https://www.ncbi.nlm.nih.gov/pubmed/28263960), which requires as input the the number of clusters to be used to aggregate cell sub-populations. Unfortunately, there is no definitive answer to this question and it represents the [*weakest aspects of performing cluster analysis*](https://hlab.stanford.edu/brian/number_of_clusters_.html). [*There are various way to try to address this issue*](http://www.sthda.com/english/articles/29-cluster-validation-essentials/96-determining-the-optimal-number-of-clusters-3-must-know-methods/), within the most conventional approaches we tested [*silhouette*](https://www.sciencedirect.com/science/article/pii/0377042787901257?via%3Dihub) and [gap statistics](http://web.stanford.edu/~hastie/Papers/gap.pdf), but none of the two approches resulted to be particularly effective (not shown). 

Another important aspect we were interested to check is the possibility that the number of clusters might change if a perturbation in cells dataset, e.g. removal of a random subset of cells, is affecting the number of clusters. Because single-cell experiment, at least today, are rarely characterized by biological replications, and frequently they represent the initial step of an analysis aimed at the identification for new cell sub-populations it is very important to assess how much stable are the cell aggregions detected by clustering.

Now a day, the best approach we could find to address the identification of the optimal number of clusters, in presence dataset perturbation, is the use of [*griph*](https://ppapasaikas.github.io/griph/), which is a hierarchical clustering algorithm. In brief, griph build a dendrogram and defines the place in which dendrogram is cut, i.e. defining the number of clusters, running a top-down similarity analysis.

Griph is used by CASC function **clusterNgriph**, which evaluates the number of clusters in which a set of cells will aggregate upon a user defined leave-\%N-out cells bootstraps. In the example below the number of clusters are detected for the file 'annotated_buettner_G1G2MS_counts_10000bis.txt', used in **Section 3.8**.

\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}
library(casc)
clusterNgriph(group="docker",scratch.folder="/data/scratch/",file=paste(getwd(), 
              "annotated_buettner_G1G2MS_counts_10000bis.txt", sep="/"), nPerm=160, 
              permAtTime=8, percent=10, separator="\t",logTen=0, seed=111)

```
\fontsize{10}{10}\selectfont

In Figure \ref{fig:fig.14a} it is shown the output generated by **clusterNgriph**. The output folder is called **Results** and it is located in the folder from which the analysis started. Within Results is present a folder named as the dataset used for the analysis. In this case 'annotated_buettner_G1G2MS_counts_10000bis'. In the latter folder is present a folder, in this specific example '5', named with the number of clusters that were more represented as result of the bootstrap analysis. The file indicated with the blue arrow contains all the information to generate the griph output plot, including all cells, that was used as reference to allocate cells to a specific cluster at each bootstrap step. The file indicated with the green arrow contains the cluster position for each cell over all bootstrap steps. The file indicated with the red arrow contains the cells removed at  each bootstrap steps.The file called 'hist.pdf', indicated with the black arrow, is the plot of the frequency of different number of clusters generated by griph as consequence of the bootstrap steps. In this specific case, over 160 permutations, 80 produced 5 clusters, 70 4 clusters and 10 6 clusters. 

```{r fig.14a, fig.cap="Output of clusterNgriph", echo=FALSE, eval=TRUE, out.width="100%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/griph3.jpeg')
```

It has to be note that in principle, since this dataset has a strong cell cycle effect, we would have expected ideally only three clusters: G1, S and G2M. This toy experiment clearly show that perturbation of the dataset under analysis can affect the number of detectable clusters. Thus, in our opinion it is mandatory to cluster cells taking in account perturbation effects to identify the clustering condition that guarantee the greatest cell stability in a cluster. In Section 4.2 we further investigate this issue. 

### **Section 4.1** Creating 4 test dataset using [*Zheng* 2016](https://community.10xgenomics.com/t5/Data-Sharing/10x-Single-Cell-3-Paper-Zheng-et-al-2016-Datasets/td-p/231) paper data.

As indicated above we are interested to identify not only the optimal cluster number but also if the cluster number is affected by removal of a random subset of cells. 
To observe the effect of datasets preturbation in clustering the we built 4 datasets combining different cell types available from [*Zheng* 2016](https://community.10xgenomics.com/t5/Data-Sharing/10x-Single-Cell-3-Paper-Zheng-et-al-2016-Datasets/td-p/231) paper:

- setA 100 cell randomly selected for each cell type:
    + B-cells (25K reads/cell), Monocytes  (100K reads/cell), **Stem cells** (24.7K reads/cell), Natural Killer cells (29K reads/cell), Naive T-cells (19K reads/cell)

- setB 100 cell randomly selected for each cell type:
    + B-cells, Monocytes, **T-helper cells** (21K reads/cell), Natural Killer, Naive T-cell
    
- setC 100 cell randomly selected for each cell type:
    + **Cytotoxic T-cells** (28.6K reads/cell), Monocytes, **T-helper cells**, Natural Killer, Naive T-cell
    
- setD 100 cell randomly selected for each cell type:
    + **Cytotoxic T-cells**, **Naive cytotoxic T-cells** (20K reads/cell), **T-helper cells**, Natural Killer, Naive T-cell
    
We used PCA (Figure \ref{fig:fig.15}A-D) to visualize the dissimilarity between cells subpopulations. PCA measures the variance between the elements of the dataset and the most important differences in variance are estimated by the PC1, which is getting smaller, i.e. cells are more similar, as we move from setA to setD. It is however important to highlight that the sequencing coverage in this experiment is quite limited, see **Section 3.2**, and providing a higher sequencing depth/cell would definetively improve the sub-populations resolution. 


\fontsize{8}{8}\selectfont    
```{r, echo=TRUE, eval=FALSE}

system("wget https://130.192.119.59/public/section4.1_examples.zip")
unzip("section4.1_examples.zip")
system("cd section4.1_examples")

#visualizing the complexity of the datasets using PCA
library(docker4seq)
topx(data.folder=getwd(),file.name="bmsnkn_5x100cells.txt",threshold=1000, logged=FALSE)
tmp <- read.table("bmsnkn_5x100cells_1000.txt", sep="\t", header=T, row.names=1)
tmp.n <- strsplit(names(tmp), "_")
tmp.n <- sapply(tmp.n, function(x)x[2])
tmp.n1 <- paste(tmp.n, seq(1:length(tmp.n)),"_",tmp.n, sep="")
names(tmp) <- tmp.n1
logtmp <- log10(tmp + 1)
write.table(logtmp, "log10_bmsnkn_5x100cells_1000.txt", sep="\t", col.names = NA)

pca(experiment.table="log10_bmsnkn_5x100cells_1000.txt", type="FPKM",
    legend.position="topleft", covariatesInNames=TRUE, samplesName=FALSE,
    principal.components=c(1,2), pdf = TRUE,
    output.folder=getwd())

topx(data.folder=getwd(),file.name="bmHnkn_5x100cells.txt",threshold=1000, logged=FALSE)
tmp <- read.table("bmHnkn_5x100cells_1000.txt", sep="\t", header=T, row.names=1)
tmp.n <- strsplit(names(tmp), "_")
tmp.n <- sapply(tmp.n, function(x)x[2])
tmp.n1 <- paste(tmp.n, seq(1:length(tmp.n)),"_",tmp.n, sep="")
names(tmp) <- tmp.n1
logtmp <- log10(tmp + 1)
write.table(logtmp, "log10_bmHnkn_5x100cells_1000.txt", sep="\t", col.names = NA)

pca(experiment.table="log10_bmHnkn_5x100cells_1000.txt", type="FPKM",
    legend.position="topleft", covariatesInNames=TRUE, samplesName=FALSE,
    principal.components=c(1,2), pdf = TRUE,
    output.folder=getwd())

topx(data.folder=getwd(),file.name="CmHnkn_5x100cells.txt",threshold=1000, logged=FALSE)
tmp <- read.table("CmHnkn_5x100cells_1000.txt", sep="\t", header=T, row.names=1)
tmp.n <- strsplit(names(tmp), "_")
tmp.n <- sapply(tmp.n, function(x)x[2])
tmp.n1 <- paste(tmp.n, seq(1:length(tmp.n)),"_",tmp.n, sep="")
names(tmp) <- tmp.n1
logtmp <- log10(tmp + 1)
write.table(logtmp, "log10_CmHnkn_5x100cells_1000.txt", sep="\t", col.names = NA)

pca(experiment.table="log10_CmHnkn_5x100cells_1000.txt", type="FPKM",
    legend.position="topleft", covariatesInNames=TRUE, samplesName=FALSE,
    principal.components=c(1,2), pdf = TRUE,
    output.folder=getwd())

topx(data.folder=getwd(),file.name="CNCHnkn_5x100cells.txt",threshold=1000, logged=FALSE)
tmp <- read.table("CNCHnkn_5x100cells_1000.txt", sep="\t", header=T, row.names=1)
tmp.n <- strsplit(names(tmp), "_")
tmp.n <- sapply(tmp.n, function(x)x[2])
tmp.n1 <- paste(tmp.n, seq(1:length(tmp.n)),"_",tmp.n, sep="")
names(tmp) <- tmp.n1
logtmp <- log10(tmp + 1)
write.table(logtmp, "log10_CNCHnkn_5x100cells_1000.txt", sep="\t", col.names = NA)

pca(experiment.table="log10_CNCHnkn_5x100cells_1000.txt", type="FPKM",
    legend.position="topleft", covariatesInNames=TRUE, samplesName=FALSE,
    principal.components=c(1,2), pdf = TRUE,
    output.folder=getwd())



```
\fontsize{10}{10}\selectfont


```{r fig.15, fig.cap="PCA is getting progressively unable to discriminate between the different cell subpopulations as the set of cells are getting functionally more similar to each other: A) PCA of setA, B) PCA of setB, C) PCA of setC, D) PCA of setD", echo=FALSE, eval=TRUE, out.width="80%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/griph1.jpeg')
```

### **Section 4.2** The number of clusters in which sub-population of cells aggregate is affected by dataset perturbations.
    
To observe the effect of the reduced dissimilarity between subset of cells on the stability of the number of clusters we use the CASC **clusterNgriph** function on the above mentioned 4 datasets using 160 permutations/each, and randomly removing in each permutation 10\% of the cells. Each analysis took approximately 60 mins on a SeqBox hardware. 

\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

#setA
clusterNgriph(group="docker",scratch.folder="/data/scratch/",file=paste(getwd(), 
              "bmsnkn_5x100cells.txt", sep="/"), nPerm=160, permAtTime=8, 
              percent=10, separator="\t",logTen=0, seed=111)

#setB
clusterNgriph(group="docker",scratch.folder="/data/scratch/",file=paste(getwd(), 
              "bmHnkn_5x100cells.txt", sep="/"), nPerm=160,
              permAtTime=8, percent=10, separator="\t",logTen=0, seed=111)

#setC
clusterNgriph(group="docker",scratch.folder="/data/scratch/",file=paste(getwd(), 
              "CmHnkn_5x100cells.txt", sep="/"), nPerm=160,
              permAtTime=8, percent=10, separator="\t",logTen=0, seed=111)

#setD
clusterNgriph(group="docker",scratch.folder="/data/scratch/",file=paste(getwd(), 
              "CNCHnkn_5x100cells.txt", sep="/"), nPerm=160,
              permAtTime=8, percent=10, separator="\t",logTen=0, seed=111)



```

\fontsize{10}{10}\selectfont

It is notable that as the differences between the cells subpopulation is getting narrowed, i.e in setA we have a very heterogeneous set of cells as in setD 4 sets out of 5 are T-cells sub-populations, the fluctuations in the detected number of clusters increase. In setA, where PCA is already able to discriminate between the different cell sub-populations, out of 160 permutations only 1 gave a number of clusters (6) different from the effective number of cell sub-populations (5) (Figure \ref{fig:fig.16}A). In set D, where four out of five sub-populations are T-cell, the clusters detected fluctuates between 3 to 5 clusters (Figure \ref{fig:fig.16}D). 

```{r fig.16, fig.cap="Clusters number stability is dependent by the cell type similarity: A) number of clusters detectable by griph in setA, B) number of clusters detectable by griph in setB, C) number of clusters detectable by griph in setC, D) number of clusters detectable by griph in setD", echo=FALSE, eval=TRUE, out.width="80%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/griph2.jpeg')
```

The difficulties in detecting a stable number of clusters is due, in our opinion, to the limited number of subpopulation specific genes detectable with a reads depths about 20-25K reads/cell. To support this hypothesis we run a comparison between the most expressed genes in cell types used in this example, using the code shown below.

\fontsize{8}{8}\selectfont
```{r, echo=TRUE, eval=FALSE}

#loading the datasets used to generate PCA
b <- read.table("cd19_b_100cell.txt", sep="\t", header=T, row.names=1)
mono <- read.table("cd14_mono_100cell.txt", sep="\t", header=T, row.names=1)
stem <- read.table("cd34_stem_100cell.txt", sep="\t", header=T, row.names=1)
nk <- read.table("cd56_nk_100cell.txt", sep="\t", header=T, row.names=1)
naiveT <- read.table("naiveT_100cell.txt", sep="\t", header=T, row.names=1)
cyto <- read.table("cytoT_100cell.txt", sep="\t", header=T, row.names=1)
naiveCyto <- read.table("naiveCytoT_100cell.txt", sep="\t", header=T, row.names=1)
helper <- read.table("cd4_h_100cell.txt", sep="\t", header=T, row.names=1)

#calculating the gene-level expression and ranking the genes from the most expressed to the least expressed
b.s <- sort(apply(b,1,sum), decreasing=T)
mono.s <- sort(apply(mono,1,sum), decreasing=T)
stem.s <- sort(apply(stem,1,sum), decreasing=T)
nk.s <- sort(apply(nk,1,sum), decreasing=T)
naiveT.s <- sort(apply(naiveT,1,sum), decreasing=T)
cyto.s <- sort(apply(cyto,1,sum), decreasing=T)
naiveCyto.s <- sort(apply(naiveCyto,1,sum), decreasing=T)
helper.s <- sort(apply(helper,1,sum), decreasing=T)

#function that measure the identity between lists of increasing lengths
overlap <- function(x,y){
  overlap.v <- NULL
  for(i in 1:length(x)){
     overlap.v[i] <- length(intersect(x[1:i], y[1:i]))
  }
  return(overlap.v)
}

#calculating the level of identity between lists of increasing lengths all comparisons are run with respect to naive T-cell.
naiveCyto.naiveT <- overlap(names(naiveT.s), names(naiveCyto.s))
b.naiveT <- overlap(names(naiveT.s), names(b.s))
mono.naiveT <- overlap(names(naiveT.s), names(mono.s))
stem.naiveT <- overlap(names(naiveT.s), names(stem.s))
nk.naiveT <- overlap(names(naiveT.s), names(nk.s))
naiveCyto.naiveT <- overlap(names(naiveT.s), names(naiveCyto.s))
helper.naiveT <- overlap(names(naiveT.s), names(helper.s))
cyto.naiveT <- overlap(names(naiveT.s), names(cyto.s))

#plotting the above data
plot(seq(1, 500), seq(1, 500), type="l", col="black", lty=2)
points(seq(1, 500), naiveCyto.naiveT[1:500], type="l", col="black")
points(seq(1, 500), cyto.naiveT[1:500], type="l", col="blue")
points(seq(1, 500), helper.naiveT[1:500], type="l", col="green")
points(seq(1, 500), mono.naiveT[1:500], type="l", col="red")
points(seq(1, 500), b.naiveT[1:500], type="l", col="brown")
points(seq(1, 500), stem.naiveT[1:500], type="l", col="orange")
points(seq(1, 500), nk.naiveT[1:500], type="l", col="violet")
legend("topleft", legend=c("Naive T-cytotoxic", "T-cytotoxic", "T-helper", "Monocytes", "B-cells", "Stem cells", "NK"),
       pch=15, col=c("black", "blue", "green", "red", "brown", "orange", "violet"))


```
\fontsize{10}{10}\selectfont


Figure \ref{fig:fig.17}  shows the number of genes found in common between naive T-cells and the other sub-populations used in setA and setD using lists of increasing size. Identity between two data sets is shown by the dashed line. The plot shows that naive T-cytotoxic, T-cytoxic and T-helper, from setD, share with naive T-cells, within the top 500 most expressed genes, more genes with respect to the other cell types present in setA. 

```{r fig.17, fig.cap="Identity between naive T-cells and the other cell types in set A and D in lists of increasing length", echo=FALSE, eval=TRUE, out.width="60%", fig.align="center"}
library(knitr)
include_graphics('../inst/img/griph4.jpeg')
```

The results describes in this section indicate that **clusterNgriph** is a valuable instrument giving information on the range of number of clusters in which to focus the analyses described in the following sections.

## **Section 5** Clustering cell sub-population by mean of kernel based similarity learning (SIMLR).



