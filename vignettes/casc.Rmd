---
title: "Single Cell workflow"
author: "Luca Alessadri, Francesca Cordero, Marco Beccuti and Raffaele A Calogero"

output: 
  rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEncoding{UTF-8}  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Single cell sequencing is a  recent technique, very powerful but not mature yet. Single cell sequencing data analysis is therefore a very dinamic field. The present workflow will undergo modifications on the basis of the availability of new tools and sequencing techniques.

The worflow is divided in two bocks: the first one designed to generate counts

![Counts generation](../inst/img/workflow0.jpeg)

and the second made to analyze counts for the identification of cell sub-population clusters. The dashed elements are those parts of the workflow not finished, yet.

![Counts analysis](../inst/img/workflow1.jpeg)

## Counts generation

- **inDropseq**:
    + Creating a reference genome for inDrop V2: **indropIndex**
    + From fastq to UMI counts using inDrop workflow: **indropCounts**

## inDrop seq

The function indropCounts starts from inDrop V2 library fastqs and generates UMI counts.

```{r, echo=TRUE, eval=FALSE}
system("wget 130.192.119.59/public/testMm_S0_L001_R1_001.fastq.gz")
system("wget 130.192.119.59/public/testMm_S0_L001_R2_001.fastq.gz")
library(casc)
indropCounts(group="docker", scratch.folder="/data/scratch", fastq.folder=getwd(),
        index.folder="/data/genomes/indropMm10", sample.name="C2", split.affixes="S2_L001",
        bowtie.index.prefix="genome", M=10, U=2, D=400, low.complexity.mask="False")

```



## Counts analysis

- **Counts manipulation**:
    + Removing non informative genes: **filterZeros**
    + Checking the genes versus total number of UMI: **genesUmi**
    + Removing low quality cells: **lorenzFilter**
    
    + Data normalization: **scnorm**, minimal requirements 10K counts/cell, works best with whole transcripts sequencing
    + Data normalization: **umiNorm**, global normalization methods TMM and RLE are suitable for UMI data
    + Converting a count table in log10: **counts2log**
    + Removing cell cycle genes: **ccremove**
    + Imputing dropouts: **cascImpute**


## Counts manipulation

### Removing non informative genes

The function **filterZeros** retains all genes that have cells without a user defined fraction of zeros (between 0 and 1, where 1 indicate only genes without 0s are retained, and 0 insted indicates that genes without any value different from zero are discarded) and plot the frequency distribution of genes with counts in the cells. 

```{r, echo=TRUE, eval=FALSE}
#downloading fastq files
system("wget http://130.192.119.59/public/singlecells_counts.txt.gz")
system("gzip -d singlecells_counts.txt.gz")
filterZeros(data.folder=getwd(),counts.matrix="singlecells_counts.txt", threshold=0)

system("wget http://130.192.119.59/public/testSCumi_mm10.csv.zip")
unzip("testSCumi_mm10.csv.zip")
tmp <- read.table("testSCumi_mm10.csv", sep=",", heqder=T, row.names=1)
dim(tmp)
#27998   806
write.table(tmp, "testSCumi_mm10.txt", sep="\t", col.names=NA)
filterZeros(data.folder=getwd(),counts.matrix="testSCumi_mm10.txt", threshold=0)
#Out of 27998 genes 11255 are left after removing genes with no counts
#output is filtered_testSCumi_mm10.txt



```

![Non zeros distribution in testSCumi_mm10.txt, orange, and in filtered_testSCumi_mm10.txt, blue](../inst/img/filterZero.jpg)


## Plotting genes numbers versus total UMIs in each cell

The function *genesUmi* produces a plot of the genes number detected, e.g. 1 gene at least 3 UMI, with respect to total number of UMI

```{r, echo=TRUE, eval=FALSE}
library(casc)
genesUmi(data.folder=getwd(), counts.matrix="filtered_testSCumi_mm10.txt", umiXgene=3)


```

In the figure below is shown the distribution of genes in cells for filtered_testSCumi_mm10.txt, i.e. a gene is called if it is supported by at least 3 UMIs.

![genesUmi output](../inst/img/genesUMI.jpg)


## Cell filtering

### Identifying outlier libraries

To identify outlier libraries, [Diaz et al.2016](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4937196/) developed a strategy to estimate genes expressed at background levels in a given sample. Then samples whose background fraction is significantly larger than average is filtered out (Lorenz statistics). Furthermore, this statistics correlates with live-dead staining, Pearson-correlation 0.7 [Diaz et al.2016](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4937196/).  

```{r, echo=TRUE,eval=FALSE}

system("wget http://130.192.119.59/public/testSCumi_mm10.csv.zip")
unzip("testSCumi_mm10.csv.zip")

library(casc)
lorenzFilter(group="docker",scratch.folder="/data/scratch/",
           data.folder=getwd(),matrixName="filtered_testSCumi_mm10",
           p_value=0.05,format="txt",separator='\t')

tmp0 <- read.table("filtered_testSCumi_mm10.txt", sep="\t", header=T, row.names=1)
#806 cells
genes <- list()
for(i in 1:dim(tmp0)[2]){
    x = rep(0, dim(tmp0)[1])
    x[which(tmp0[,i] >=  3)] <- 1
    genes[[i]] <- x
}
genes <- as.data.frame(genes)
genes.sum <-  apply(genes,2, sum)
umi.sum <- apply(tmp0,2, sum)

plot(log10(umi.sum), genes.sum, xlab="log10 UMI", ylab="# of genes")
points(log10(umi.sum), genes.sum, pch=19, cex=0.5, col="blue")

tmp <- read.table("lorenz_filtered_testSCumi_mm10.txt", sep="\t", header=T, row.names=1)
#785 cells
genes <- list()
for(i in 1:dim(tmp)[2]){
    x = rep(0, dim(tmp)[1])
    x[which(tmp[,i] >=  3)] <- 1
    genes[[i]] <- x
}
genes <- as.data.frame(genes)
genes.sum <-  apply(genes,2, sum)
umi.sum <- apply(tmp,2, sum)
points(log10(umi.sum), genes.sum, pch=19, cex=0.5, col="red")


```


![Effect of Lorenz filtering. Cells shown in blue have been discarded because of their too low quality](../inst/img/lorenz_filter.jpg)



### Data normalization

[The best way to normalize single-cell RNA-seq data has not yet been resolved](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5549838/), expecially for UMI data. We inserted in our workflow two possible options:

- [SCnorm](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5473255/), which works best with whole transcript data.

- [scone](https://www.biorxiv.org/content/early/2017/12/16/235382), which provides different global scaling methods that can be applyed to UMI single-cell data.

#### SCnorm

[SCnorm](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5473255/) performs a quantile-regression based approach for robust normalization of single-cell RNA-seq data.  SCnorm groups genes based on their count-depth relationship then applies a quantile regression to each group in order to estimate scaling factors which will remove the effect of sequencing depth from the counts.

IMPORTANT: SCnorm is not intended for datasets with more than ~80% zero counts, often K will not converge in these situations. 

##### Check counts-depth relationship

Before normalizing using **scnorm**, it is advised to check the data count-depth relationship.
If all genes have a similar relationship then a global normalization strategy such as median-by-
ratio in the DESeq package or TMM in edgeR will also be adequate. However, when the count-depth relationship varies among genes using global scaling strategies leads to poor normalization. In these cases the normalization provided by SCnorm is reccomanded.

**checkCountDepth** provides a wrapper, in CASC, for the checkCountDepth of the [**SCnorm package**](https://github.com/rhondabacher/SCnorm), which estimates the count-depth relationship for all genes.

```{r, echo=TRUE, eval=FALSE}
system("wget http://130.192.119.59/public/example_UMI.txt.zip")
unzip("example_UMI.txt.zip")
conditions=rep(1,12)
checkCountDepth(group="docker", data.folder=getwd(), counts.matrix="example_UMI.txt",
     conditions=conditions, FilterCellProportion=0.1, FilterExpression=0,
     ditherCounts=TRUE, outputName="example_UMI", nCores=8)

```

The output is a PDF that provides a view of the counts distribution of the data and a file selected.genes.txt, which contains the genes selected to run the analysis.


![checkCountDepth output](../inst/img/checkCountDepth0.jpg)

#### scnorm

the **scnorm** function execute SCnorm of the [**SCnorm package**](https://github.com/rhondabacher/SCnorm), which normalizes  across  cells  to  remove  the effect  of  sequencing  depth  on  the  counts  and  return  the  normalized expression count.

```{r, echo=TRUE, eval=FALSE}
system("wget http://130.192.119.59/public/example_UMI.txt.zip")
unzip("example_UMI.txt.zip")
#this specific example is an UMI sequence but all 12 cells have at least 10000 UMI.
conditions=rep(1,12)
scnorm(group="docker", data.folder=getwd(),counts.matrix="example_UMI.txt",
     conditions=conditions,outputName="example_UMI", nCores=8, filtercellNum=10,
     ditherCount=TRUE, PropToUse=0.1, PrintProgressPlots=TRUE, FilterExpression=1)

```

The output is file, *discarded_genes.txt*, which contains the discarded genes and a tab delimited file containing the normalized data, with the prefix *normalized_*.

![SCnorm effect.](../inst/img/scnorm.jpg)

#### scone

scone package embeds:

- Centered log-ratio (CLR) normalization 

- Relative log-expression (RLE; DESeq) scaling normalization

    + the scaling factors are calculated for each lane as median of the ratio, for each gene, of its read count of its geometric mean across all lanes. 

- Full-quantile normalization

    + quantile normalization is a technique for making two or more distributions identical in statistical properties. To quantile normalize two or more samples to each other, sort the samples, then set to the average (usually, arithmetic mean) of the samples. So the highest value in all cases becomes the mean of the highest values, the second highest value becomes the mean of the second highest values, and so on.

- Simple deconvolution normalization 

- Sum scaling normalization

    + Gene counts are divided by the total number of mapped reads (or library size) associated with their lane and multiplied by the mean total count across all the samples of the dataset.

- Weighted trimmed mean of M-values (TMM, edgeR) scaling normalization

    + to compute the TMM factor, one lane is considered a reference sample and the others test samples, with TMM being the weighted mean of log ratios between test and reference, after excluding the most expressed genes and the genes with the largest log ratios. 

- Upper-quartile (UQ) scaling normalization

    + the total counts are replaced by the upper quartile of counts different from 0 in the computation of the normalization factors.


```{r, echo=TRUE, eval=FALSE}

#Weighted trimmed mean of M-values (TMM) scaling normalization
system("wget http://130.192.119.59/public/example_UMI.txt.zip")
unzip("example_UMI.txt.zip")
umiNorm(group="docker", data.folder=getwd(), counts.matrix="example_UMI.txt",
     outputName="example_UMI", normMethod="TMM_FN")

```




### Imputing dropouts 

the **cascImpute** function execute scImpute of the [**scImpute package**](https://github.com/Vivianstats/scImpute), which impute the dropout values in scRNA-seq data.

```{r, echo=TRUE, eval=FALSE}
#downloading fastq files
system("wget http://130.192.119.59/public/singlecells_counts.txt.gz")
system("gzip -d singlecells_counts.txt.gz")
cascImpute(group="docker", data.folder=getwd(), counts.matrix="singlecells_counts.txt", drop.thre=0.5, cores=8)

#Modifying drop.thre value A quick version of the imputing can be used to refine drop.thre values indicating refining=TRUE. It has to be done in the same folder where the frst run was done.
cascImpute(group="docker", data.folder=getwd(), counts.matrix="singlecells_counts.txt", drop.thre=0.3, cores=8, refining=TRUE)
```

The output is a matrix file containing the imputed data. 



### Converting a count table in log10

The function **counts2log** can convert a count table in a log10 values saved in a comma separated or tab delimited file.

```{r, echo=TRUE, eval=FALSE}
#downloading fastq files
system("wget http://130.192.119.59/public/singlecells_counts.txt.gz")
system("gzip -d singlecells_counts.txt.gz")
counts2log(counts.matrix="singlecells_counts.txt", data.folder=getwd(), 
           log.base=10, type="txt")
```





#### Defining the optimal number of clusters

An important step in the single-cell transcriptome analysis is to group cells that belong to the same type based on gene expression patterns [Usoskin et al, Pollen et al, Kolodziejczyk et al].
This can be done using supervised and unsupervised clustering. A lot of tools are actually available for single-cell transcriptome clustering [ref]. At the present time we have implemented tSne and SIMLR.

```{r, echo=TRUE, eval=FALSE}
#downloading fastq files
system("wget http://130.192.119.59/public/log10_singlecells_counts.csv.gz")
system("gzip -d log10_singlecells_counts.csv.gz")

cascKoptimization(group="docker", scratch.folder="/Users/raffaelecalogero/Desktop/scratch", data.folder=getwd(),
counts.matrix="log10_singlecells_counts.csv", permutations=20, blocks.permutations=2, core=0, bootstrap.fraction=10, k.min=2, k.max=4, totIdentity=80, clusterIdentity=80)

```

The function **cascKoptimization** run SIMLR [Wang et al] using a range of clusters and produces as output two violin plots:

- silhouette.pdf: Silhouette refers to a method of interpretation and validation of consistency within clusters of data. The technique provides a succinct graphical representation of how well each object lies within its cluster. Here instead of using the average silhouette we represent the silhouette values distribution using a violin plot. Thus, silhouette distributions being skewed to the positive values and with short negative tail is representative of a consistent cluster. In the example below, fig. A, it seems that 4 clusters are the most consistent by silhouette analysis.


- cell.stability.pdf: Cell stability plot represent the distribution of the fraction of times, given a N number of permutations, that the cell are stabily localized in a cluster. The example below, fig. B, 3 clusters are characterized by an higher cell stability with respect to 4 clusters. 

Taking in account the two plots and the clusters structure observed for 3 and 4 clusters, fig C and D, it is clear that 4 clusters provide a better separation between cells but keeping very high the cell permanence in a cluster.



The function **cascOutputReformat** use SilhouetteParameters.csv (the file containing the cell silhouette scores), mainVector.csv (the file that associates each cell to a specific SIMLR cluster), scoreVector.csv (the file associating each cell to a specific cell stability score), dataPlot.csv (containing SIMLR component 1 and 2 cohordinates) to generate a summary file called **summary_table.csv**.

```{r, echo=TRUE, eval=FALSE}
 #downloading fastq files
system("wget http://130.192.119.59/public/example.zip")
unzip("example.zip")
setwd("./example")
cascOutputReformat(data.folder=getwd())
```











